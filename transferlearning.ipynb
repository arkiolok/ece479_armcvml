{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2IQ2J1tCEM_j"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as premobilenet\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input as prexception\n",
        "\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input as prenasnet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yzkd046_aSZy"
      },
      "outputs": [],
      "source": [
        "model_no = 1\n",
        "model_type = [MobileNetV2, Xception, NASNetLarge][model_no]\n",
        "preprocess_input = [premobilenet, prexception, prenasnet][model_no]\n",
        "model_name = ['MobileNetV2', 'Xception', 'NASNetLarge'][model_no]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZZ1VbVeGCFjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cdde79-db71-465b-ab78-5f85b3bb30ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load the MobileNetV2 model with pre-trained weights from ImageNet and remove the last layer\n",
        "input_shape = (96, 96)\n",
        "base_model = model_type(weights='imagenet', include_top=False, input_shape=input_shape+(3,))\n",
        "base_model.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTi1WY5CEM_k",
        "outputId": "d92c63c4-317e-4717-aebd-9dddb261bf93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if \"GPU\" not in device_name:\n",
        "    print(\"GPU device not found\")\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QylHLSEM_l",
        "outputId": "73c0f132-b0fb-4502-c9a8-22b398e16b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "# load and preprocess the CIFAR100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "print(x_train.dtype)\n",
        "data_augmentation = keras.Sequential(\n",
        "    \n",
        "    [layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.Resizing(*input_shape, interpolation=\"bilinear\", crop_to_aspect_ratio=False),\n",
        "    layers.RandomCrop(*input_shape, seed=None)\n",
        "\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NjZIOIchEM_m"
      },
      "outputs": [],
      "source": [
        "# add new classification layers for CIFAR100\n",
        "inputs = keras.Input(shape=(32,32,3))\n",
        "x = preprocess_input(inputs)\n",
        "x = data_augmentation(x)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "outputs = Dense(100, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIZJ9CzS7fh1",
        "outputId": "eaaec698-9429-459e-b6f4-7cf9d3be5cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 73s 38ms/step - loss: 2.7945 - sparse_categorical_accuracy: 0.3163 - val_loss: 1.9951 - val_sparse_categorical_accuracy: 0.4762\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 2.3396 - sparse_categorical_accuracy: 0.3966 - val_loss: 1.9155 - val_sparse_categorical_accuracy: 0.4862\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 2.2220 - sparse_categorical_accuracy: 0.4175 - val_loss: 1.8808 - val_sparse_categorical_accuracy: 0.5001\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 2.1520 - sparse_categorical_accuracy: 0.4329 - val_loss: 1.8489 - val_sparse_categorical_accuracy: 0.5043\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 2.1025 - sparse_categorical_accuracy: 0.4423 - val_loss: 1.8444 - val_sparse_categorical_accuracy: 0.5048\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 2.0551 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.8510 - val_sparse_categorical_accuracy: 0.5062\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 2.0143 - sparse_categorical_accuracy: 0.4636 - val_loss: 1.8179 - val_sparse_categorical_accuracy: 0.5147\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.9800 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.8165 - val_sparse_categorical_accuracy: 0.5145\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.9450 - sparse_categorical_accuracy: 0.4753 - val_loss: 1.8375 - val_sparse_categorical_accuracy: 0.5084\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.9390 - sparse_categorical_accuracy: 0.4795 - val_loss: 1.8235 - val_sparse_categorical_accuracy: 0.5154\n"
          ]
        }
      ],
      "source": [
        "# train the model and evaluate its accuracy and inference time\n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "1DoRVDT3NJQj",
        "outputId": "107fce34-b41d-4dee-cb19-db5e97c15699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 223s 120ms/step - loss: 1.5327 - sparse_categorical_accuracy: 0.5711 - val_loss: 1.3544 - val_sparse_categorical_accuracy: 0.6169\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 185s 119ms/step - loss: 1.3159 - sparse_categorical_accuracy: 0.6225 - val_loss: 1.2460 - val_sparse_categorical_accuracy: 0.6447\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 1.1945 - sparse_categorical_accuracy: 0.6548 - val_loss: 1.1729 - val_sparse_categorical_accuracy: 0.6629\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 1.0994 - sparse_categorical_accuracy: 0.6765 - val_loss: 1.1227 - val_sparse_categorical_accuracy: 0.6758\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 1.0148 - sparse_categorical_accuracy: 0.6969 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.6882\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 0.9464 - sparse_categorical_accuracy: 0.7146 - val_loss: 1.0748 - val_sparse_categorical_accuracy: 0.6960\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 183s 117ms/step - loss: 0.8823 - sparse_categorical_accuracy: 0.7345 - val_loss: 1.0470 - val_sparse_categorical_accuracy: 0.7006\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 183s 117ms/step - loss: 0.8302 - sparse_categorical_accuracy: 0.7511 - val_loss: 1.0622 - val_sparse_categorical_accuracy: 0.7044\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 0.7807 - sparse_categorical_accuracy: 0.7627 - val_loss: 1.0356 - val_sparse_categorical_accuracy: 0.7108\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 185s 118ms/step - loss: 0.7321 - sparse_categorical_accuracy: 0.7735 - val_loss: 1.0442 - val_sparse_categorical_accuracy: 0.7155\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 184s 118ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7858 - val_loss: 1.0287 - val_sparse_categorical_accuracy: 0.7210\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 185s 119ms/step - loss: 0.6438 - sparse_categorical_accuracy: 0.8008 - val_loss: 1.0183 - val_sparse_categorical_accuracy: 0.7246\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 185s 119ms/step - loss: 0.6137 - sparse_categorical_accuracy: 0.8090 - val_loss: 1.0210 - val_sparse_categorical_accuracy: 0.7253\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 186s 119ms/step - loss: 0.5745 - sparse_categorical_accuracy: 0.8205 - val_loss: 1.0367 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 186s 119ms/step - loss: 0.5429 - sparse_categorical_accuracy: 0.8284 - val_loss: 1.0258 - val_sparse_categorical_accuracy: 0.7295\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nstart_time = time.time()\\nloss, accuracy = model.evaluate(x_test, y_test)\\nend_time = time.time()\\ninference_time = end_time - start_time\\nprint('Accuracy:', accuracy)\\nprint('Inference time:', inference_time)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])    \n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "    model.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_test, y_test), ) # 20 epochs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "start_time = time.time()\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "end_time = time.time()\n",
        "inference_time = end_time - start_time\n",
        "print('Accuracy:', accuracy)\n",
        "print('Inference time:', inference_time)\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mqECHWZKEM_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e08c82-f5d0-4e9f-e5bf-8dcebf3315de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/10000 [==============================] - 84s 8ms/step - loss: 1.0258 - sparse_categorical_accuracy: 0.7295\n",
            "Accuracy: 0.7294999957084656\n",
            "Inference time: 0.014209563064575196\n",
            "FPS: 70.37514070316671\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=1)\n",
        "end_time = time.time()\n",
        "inference_time = end_time - start_time\n",
        "print('Accuracy:', accuracy)\n",
        "print('Inference time:', inference_time/10000)\n",
        "print(\"FPS:\", 1/(inference_time/10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wi2cRVFHN29E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7190a30a-30ec-48b0-df79-8ca1792167ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p9QNeG2-cECW"
      },
      "outputs": [],
      "source": [
        "def representative_dataset():\n",
        "  for data in tf.data.Dataset.from_tensor_slices(x_train.astype(np.float32)).batch(1).take(100):\n",
        "    yield [data]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(model_name)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_quant_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gT2wtNDydTxv"
      },
      "outputs": [],
      "source": [
        "with open(model_name+'.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qlWfoPnJlyC",
        "outputId": "9e93adea-54b5-408c-ceb2-5d8679e54586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "#x_train, x_test = x_train.astype(np.int8)/255, x_test.astype(np.int8)/255\n",
        "#x_train = tf.keras.applications.mobilenet_v2.preprocess_input(x_train)\n",
        "\n",
        "# x_train, x_test = (x_train/255).astype(np.int8), (x_test/255).astype(np.int8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdJRFMWYZhhE"
      },
      "source": [
        "# Test with TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgHaAJCmS10f",
        "outputId": "91dbe258-a419-40df-f163-94dcca28ce8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.uint8'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(33, 0.005614476000118884)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=model_name+'.tflite')\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "import time\n",
        "\n",
        "def r(im, interpreter = interpreter, print_input_type = 0):\n",
        "\n",
        "  # Allocate tensors\n",
        "  interpreter.allocate_tensors()\n",
        "  # If the expected input type is int8 (quantized model), rescale data\n",
        "  input_type = input_details[0]['dtype']\n",
        "  if print_input_type: print(input_type)\n",
        "  input_shape = input_details[0][\"shape\"]\n",
        "  im1 = im.astype(input_type)\n",
        "  #print(input_type)\n",
        "  start = time.perf_counter()\n",
        "  interpreter.set_tensor(input_details[0]['index'], im1.reshape(input_shape))\n",
        "\n",
        "  # Run inference\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # output_details[0]['index'] = the index which provides the input\n",
        "  output = interpreter.get_tensor(output_details[0]['index'])\n",
        "  end = time.perf_counter()\n",
        "  return output.argmax(), (end-start)\n",
        "r(x_test[1,:,:,:], print_input_type=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m3v9-mDKRQL"
      },
      "outputs": [],
      "source": [
        "preds = np.zeros(10000)\n",
        "\n",
        "start = time.perf_counter()\n",
        "\n",
        "lat1 = 0\n",
        "for i in range(10000):\n",
        "  pred, lat = r(x_test[i,:,:,:])\n",
        "  lat1+=lat\n",
        "  preds[i] = pred\n",
        "\n",
        "lat2 = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Uzasxla-VW",
        "outputId": "e4f34155-11e6-4748-bf4b-43ca0dd560a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.029510787999243 4.054668900000024\n",
            "fps: 248.16908369577192 246.6292623794742\n"
          ]
        }
      ],
      "source": [
        "print(lat1, lat2)\n",
        "print(\"fps:\", 1/(lat1/10000), 1/(lat2/10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Dgss40LCjG",
        "outputId": "3d58e4d8-11a3-4167-e141-fda5b3242e93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([68.,  8., 55., ..., 38., 42., 54.])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHGEvwR6LNZK",
        "outputId": "e68d36b8-ae4d-47fa-8b16-65c9c16cc60c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6052"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(y_test[:10000].T == preds).sum()\n",
        "print(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9-eJjv5MBhm"
      },
      "outputs": [],
      "source": [
        "np.save('x_test.npy', x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zGFPOVgHC27"
      },
      "outputs": [],
      "source": [
        "np.save(\"y_test.npy\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-cm6YfUHE4q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}